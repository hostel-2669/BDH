{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99d8a28-b811-415c-99f3-6c457061b61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import random, time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace2c35a-a03d-4b16-97f9-1dab4e1fd92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPH = b\"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n",
    "ALPH_SET = set(ALPH)\n",
    "\n",
    "def make_noise(noise_len: int) -> bytes:\n",
    "    out = bytearray()\n",
    "    while len(out) < noise_len:\n",
    "        b = os.urandom(1)[0]\n",
    "        if b == 10:\n",
    "            continue\n",
    "        if b in ALPH_SET:\n",
    "            continue\n",
    "        out.append(b)\n",
    "    return bytes(out)\n",
    "\n",
    "def rand_pw(pw_len=6):\n",
    "    return bytes(ALPH[b % len(ALPH)] for b in os.urandom(pw_len))\n",
    "\n",
    "def bytes_to_tokens(b: bytes):\n",
    "    return torch.tensor(list(b), dtype=torch.long)\n",
    "\n",
    "def make_sample(noise_len: int, pw_len: int = 6):\n",
    "    pw = rand_pw(pw_len)\n",
    "\n",
    "    noise = b\"NOISE=\" + make_noise(noise_len) + b\"\\n\"\n",
    "    prompt_bytes = (\n",
    "        b\"PASSWORD=\" + pw + b\"\\n\" +\n",
    "        noise +\n",
    "        b\"Q:WHAT_IS_PASSWORD?\\nA:\"\n",
    "    )\n",
    "    full_bytes = prompt_bytes + pw\n",
    "\n",
    "    seq = bytes_to_tokens(full_bytes)\n",
    "    prompt = bytes_to_tokens(prompt_bytes)\n",
    "    x = seq[:-1]\n",
    "    y = seq[1:]\n",
    "\n",
    "    m = torch.zeros_like(y, dtype=torch.bool)\n",
    "    m[-pw_len:] = True\n",
    "\n",
    "    return x, y, m, pw, prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63dc34e-1b28-436f-8dad-a5f3632f1f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryRetentionModel(nn.Module):\n",
    "    def __init__(self, vocab_size=256, d_model=256, nhead=8, num_layers=4):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.token_embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embed = nn.Embedding(4096, d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=d_model * 4,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "\n",
    "\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=d_model * 4,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers)\n",
    "\n",
    "\n",
    "        self.head = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "    def forward(self, x, memory_mask=None):\n",
    "        B, T = x.shape\n",
    "        positions = torch.arange(T, device=x.device).unsqueeze(0)\n",
    "        x = self.token_embed(x) + self.pos_embed(positions)\n",
    "        memory = self.encoder(x)\n",
    "        output = self.decoder(x, memory)\n",
    "\n",
    "        return self.head(output)\n",
    "\n",
    "model = MemoryRetentionModel(\n",
    "    vocab_size=256,\n",
    "    d_model=256,\n",
    "    nhead=8,\n",
    "    num_layers=4\n",
    ").to(device)\n",
    "\n",
    "print(f\" Model: {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "print(f\" Encoder-Decoder with cross-attention for memory retrieval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1332c5aa-dae8-4f32-9564-ac44f01518ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_pw(n=6):\n",
    "    chars = b\"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n",
    "    return bytes(chars[random.randint(0, len(chars)-1)] for _ in range(n))\n",
    "\n",
    "def make_sample(noise_len: int, pw_len: int = 6):\n",
    "    pw = rand_pw(pw_len)\n",
    "    prefix = b\"PASSWORD=<<<\" + pw + b\">>>\\n\"\n",
    "    noise  = b\"NOISE=\" + make_noise(noise_len) + b\"\\n\"\n",
    "    query  = b\"Q:WHAT_IS_PASSWORD?\\nA:<<<\"\n",
    "\n",
    "    prompt_bytes = prefix + noise + query\n",
    "    full_bytes   = prompt_bytes + pw + b\">>>\"\n",
    "    seq    = bytes_to_tokens(full_bytes)\n",
    "    prompt = bytes_to_tokens(prompt_bytes)\n",
    "\n",
    "    x = seq[:-1]\n",
    "    y = seq[1:]\n",
    "\n",
    "    m = torch.zeros_like(y, dtype=torch.bool)\n",
    "    m[-(pw_len+3):-3] = True\n",
    "\n",
    "    return x, y, m, pw, prompt\n",
    "\n",
    "print(\"Data generation ready\")\n",
    "print(\" Format: [START][password][SEP][noise][SEP][password][END]\")\n",
    "print(' encode_bytes: (x % 252) + 4  ‚Üí  always in [4, 255]  ‚Üê FIX-2')\n",
    "\n",
    "for _ in range(200):\n",
    "    x, y, m, pw, prompt = make_sample(noise_len=512)\n",
    "    assert x.max().item() <= 259, f'Token out of range: {x.max().item()}'\n",
    "    assert x.min().item() >= 0,   f'Negative token: {x.min().item()}'\n",
    "print('‚úÖ Sanity check passed ‚Äî all tokens in [0, 259]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcf80f0-13b9-4871-8050-17345cd850d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.amp import autocast, GradScaler\n",
    "import gc, time, random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "ALPH = b\"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n",
    "ALPH_SET = set(ALPH)\n",
    "\n",
    "def make_noise(noise_len: int) -> bytes:\n",
    "    out = bytearray()\n",
    "    while len(out) < noise_len:\n",
    "        b = os.urandom(1)[0]\n",
    "        if b == 10:\n",
    "            continue\n",
    "        if b in ALPH_SET:\n",
    "            continue\n",
    "        out.append(b)\n",
    "    return bytes(out)\n",
    "\n",
    "ALLOWED = torch.tensor(list(ALPH), dtype=torch.long)\n",
    "\n",
    "def rand_pw(pw_len=6):\n",
    "    return bytes(ALPH[b % len(ALPH)] for b in os.urandom(pw_len))\n",
    "\n",
    "def bytes_to_tokens(b: bytes):\n",
    "    return torch.tensor(list(b), dtype=torch.long)\n",
    "\n",
    "def make_sample(noise_len: int, pw_len: int = 6):\n",
    "    pw = rand_pw(pw_len)\n",
    "\n",
    "    prefix = b\"PASSWORD=<<<\" + pw + b\">>>\\n\"\n",
    "    noise  = b\"NOISE=\" + make_noise(noise_len) + b\"\\n\"\n",
    "    query  = b\"Q:WHAT_IS_PASSWORD?\\nA:<<<\"\n",
    "\n",
    "    prompt_bytes = prefix + noise + query\n",
    "    full_bytes   = prompt_bytes + pw + b\">>>\"\n",
    "\n",
    "    seq    = bytes_to_tokens(full_bytes)\n",
    "    prompt = bytes_to_tokens(prompt_bytes)\n",
    "\n",
    "    x = seq[:-1]\n",
    "    y = seq[1:]\n",
    "\n",
    "    m = torch.zeros_like(y, dtype=torch.bool)\n",
    "    m[-(pw_len+3):-3] = True\n",
    "\n",
    "    return x, y, m, pw, prompt\n",
    "\n",
    "def train_proper(model, total_steps=3000, base_batch=16, lr=3e-4):\n",
    "    model.train()\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01, betas=(0.9, 0.98))\n",
    "    scaler = GradScaler(\"cuda\", enabled=(device.type == \"cuda\"))\n",
    "\n",
    "    def get_noise_and_batch(step):\n",
    "        progress = step / total_steps\n",
    "        if progress < 0.25:\n",
    "            return 0, base_batch\n",
    "        elif progress < 0.40:\n",
    "            return random.randint(0, 128), base_batch\n",
    "        elif progress < 0.55:\n",
    "            return random.randint(64, 512), max(8, base_batch // 2)\n",
    "        elif progress < 0.70:\n",
    "            return random.randint(256, 1024), max(4, base_batch // 4)\n",
    "        elif progress < 0.85:\n",
    "            return random.randint(512, 1536), 4\n",
    "        else:\n",
    "            return random.randint(1024, 2048), 2\n",
    "\n",
    "    start_time = time.time()\n",
    "    best_acc = 0.0\n",
    "    current_phase = -1\n",
    "\n",
    "    print(\"\\n Starting training with 6 phases...\\n\")\n",
    "\n",
    "    for step in range(1, total_steps + 1):\n",
    "        noise_len, batch_size = get_noise_and_batch(step)\n",
    "\n",
    "        new_phase = int((step / total_steps) * 6)\n",
    "        if new_phase != current_phase:\n",
    "            current_phase = new_phase\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"PHASE {current_phase + 1}/6 starting at step {step}\")\n",
    "            print(f\"{'='*60}\\n\")\n",
    "\n",
    "        # build batch\n",
    "        xs, ys, ms = [], [], []\n",
    "        for _ in range(batch_size):\n",
    "            x1, y1, m1, _, _ = make_sample(noise_len)\n",
    "            xs.append(x1); ys.append(y1); ms.append(m1)\n",
    "\n",
    "        maxT = max(t.numel() for t in xs)\n",
    "\n",
    "        def pad(t, T):\n",
    "            if t.numel() < T:\n",
    "                return torch.cat([t, torch.zeros(T - t.numel(), dtype=t.dtype)])\n",
    "            return t\n",
    "\n",
    "        x = torch.stack([pad(t, maxT) for t in xs]).to(device)\n",
    "        y = torch.stack([pad(t, maxT) for t in ys]).to(device)\n",
    "        m = torch.stack([pad(t, maxT).bool() for t in ms]).to(device)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "\n",
    "        try:\n",
    "            with autocast(\"cuda\", enabled=(device.type == \"cuda\")):\n",
    "                out = model(x)\n",
    "                if isinstance(out, tuple):\n",
    "                    out = out[0]\n",
    "                logits = out[m]\n",
    "                targets = y[m]\n",
    "                loss = F.cross_entropy(logits, targets)\n",
    "                m = torch.stack([pad(t, maxT).bool() for t in ms]).to(device)  # (B,T)\n",
    "\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(opt)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(opt)\n",
    "            scaler.update()\n",
    "\n",
    "            loss_val = float(loss.item())\n",
    "            acc_val = float((logits.argmax(-1) == targets).float().mean().item())\n",
    "            best_acc = max(best_acc, acc_val)\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            if \"out of memory\" in str(e).lower():\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "                continue\n",
    "            raise\n",
    "\n",
    "\n",
    "        if step % 50 == 0 or step == total_steps:\n",
    "            elapsed = time.time() - start_time\n",
    "            status = \"‚úÖ\" if acc_val > 0.7 else (\"üü°\" if acc_val > 0.4 else \"‚ö†Ô∏è\")\n",
    "            mem_str = \"\"\n",
    "            if torch.cuda.is_available():\n",
    "                mem = torch.cuda.memory_allocated(0) / 1e9\n",
    "                mem_str = f\"Mem:{mem:.1f}GB\"\n",
    "            print(f\"{status} [{step:4d}/{total_steps}] Loss:{loss_val:.3f} Acc:{acc_val:.3f} \"\n",
    "                  f\"Noise:{noise_len:4d} Batch:{batch_size:2d} Time:{elapsed:.0f}s {mem_str}\")\n",
    "\n",
    "        # milestone test\n",
    "        if step in [750, 1500, 2250, 3000]:\n",
    "            print(f\"\\nüìä COMPREHENSIVE TEST at step {step}:\")\n",
    "            for tn in [0, 128, 512, 1024, 2048]:\n",
    "                exact = test_quick(model, tn, n=20)\n",
    "                bar = \"‚ñà\" * int(exact * 30)\n",
    "                print(f\"   Noise {tn:4d}: {exact:5.1%} {bar}\")\n",
    "            print()\n",
    "\n",
    "            model.train()\n",
    "\n",
    "        del x, y, m, out, logits, targets, loss\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"\\n‚úÖ Training complete. Best accuracy: {best_acc:.3f}\")\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_quick(model, noise_len, n=20, pw_len=6):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for _ in range(n):\n",
    "        x,y,m,pw,prompt = make_sample(noise_len, pw_len=6)\n",
    "        pred = generate(model, prompt, 6)\n",
    "        if pred == pw:\n",
    "            correct += 1\n",
    "    return correct / n\n",
    "\n",
    "\n",
    "def generate(model, prompt, pw_len=6):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    ctx = prompt.to(device).unsqueeze(0)  # (1, T)\n",
    "    out_bytes = []\n",
    "\n",
    "    allowed = ALLOWED.to(device)  # (36,)\n",
    "\n",
    "    for _ in range(pw_len):\n",
    "        out = model(ctx)\n",
    "        if isinstance(out, tuple):  # if your BDH returns (logits, extra)\n",
    "            out = out[0]\n",
    "        logits = out[0, -1]  # (V,)\n",
    "\n",
    "        # ---- CONSTRAIN TO ALPHABET ONLY ----\n",
    "        allowed_logits = logits[allowed]                 # (36,)\n",
    "        idx = int(torch.argmax(allowed_logits).item())   # greedy\n",
    "        next_tok = int(allowed[idx].item())              # map back to real token (0..255)\n",
    "\n",
    "        out_bytes.append(next_tok)\n",
    "        ctx = torch.cat([ctx, torch.tensor([[next_tok]], device=device)], dim=1)\n",
    "\n",
    "    return bytes(out_bytes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36ec364-6fc7-4c91-b81d-4dd728b2d20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Starting comprehensive training...\")\n",
    "print(\" This will take 15-20 minutes but covers ALL noise levels\")\n",
    "print(\" Testing at steps 750, 1500, 2250, and 3000\\n\")\n",
    "\n",
    "model = train_proper(model, total_steps=3000, base_batch=16, lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c235be-9a10-4b95-87a6-6b900c5f7296",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def final_comprehensive_test(model):\n",
    "    model.eval()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"FINAL COMPREHENSIVE TEST - ALL NOISE LEVELS\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    for noise_len in [0, 128, 512, 1024, 1536, 2048]:\n",
    "        print(f\"\\n{'‚îÄ'*70}\")\n",
    "        print(f\"Noise: {noise_len} bytes\")\n",
    "        print(f\"{'‚îÄ'*70}\")\n",
    "\n",
    "        exact = 0\n",
    "        good = 0  # 4+ chars\n",
    "        partial = 0  # 2+ chars\n",
    "        total_chars = 0\n",
    "\n",
    "        # Loop 10 times for each noise level to get stats\n",
    "        for i in range(10): # Changed from 5 to 10 tests per noise level\n",
    "            x,y,m,pw,prompt = make_sample(noise_len, pw_len=6) # Use current noise_len\n",
    "            pred = generate(model, prompt, 6) # Use 'model' parameter\n",
    "            # Optional debug print:\n",
    "            # print(\"true:\", pw.decode(), \"pred:\", pred.decode(), \"match:\", sum(a==b for a,b in zip(pw,pred)))\n",
    "\n",
    "            chars_correct = sum(a == b for a, b in zip(pw, pred))\n",
    "            total_chars += chars_correct\n",
    "\n",
    "            if pred == pw:\n",
    "                exact += 1\n",
    "                good += 1\n",
    "                partial += 1\n",
    "                status = \"‚úÖ\"\n",
    "            elif chars_correct >= 4:\n",
    "                good += 1\n",
    "                partial += 1\n",
    "                status = \"üü¢\"\n",
    "            elif chars_correct >= 2:\n",
    "                partial += 1\n",
    "                status = \"üü°\"\n",
    "            else:\n",
    "                status = \"‚ùå\"\n",
    "\n",
    "            print(f\"  {status} {i+1:2d}. {pw.decode('latin1')} ‚Üí \"\n",
    "                  f\"{pred.decode('latin1', errors='replace')} ({chars_correct}/6)\")\n",
    "\n",
    "        avg_chars = total_chars / 60  # 10 tests * 6 chars\n",
    "\n",
    "        print(f\"\\n  üìä Results:\")\n",
    "        print(f\"     Exact (6/6):  {exact}/10 ({exact*10}%)\")\n",
    "        print(f\"     Good (‚â•4/6):  {good}/10 ({good*10}%)\")\n",
    "        print(f\"     Partial (‚â•2): {partial}/10 ({partial*10}%)\")\n",
    "        print(f\"     Avg chars:    {avg_chars:.1%}\")\n",
    "\n",
    "        all_results.append((noise_len, exact/10, good/10, partial/10, avg_chars))\n",
    "\n",
    "    # Summary\n",
    "    print(f\"\\n\\n{'='*70}\")\n",
    "    print(\"SUMMARY ACROSS ALL NOISE LEVELS\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"{'Noise':<10} {'Exact':<12} {'Good (‚â•4)':<12} {'Partial (‚â•2)':<15} {'Avg Chars'}\")\n",
    "    print(\"‚îÄ\" * 70)\n",
    "\n",
    "    for noise, exact, good, partial, avg in all_results:\n",
    "        print(f\"{noise:<10} {exact:<12.1%} {good:<12.1%} {partial:<15.1%} {avg:.1%}\")\n",
    "\n",
    "    overall_exact = sum(r[1] for r in all_results) / len(all_results)\n",
    "    overall_chars = sum(r[4] for r in all_results) / len(all_results)\n",
    "\n",
    "    print(\"‚îÄ\" * 70)\n",
    "    print(f\"{'AVERAGE':<10} {overall_exact:<12.1%} {'':<12} {'':<15} {overall_chars:.1%}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    print(\"\\nüìä INTERPRETATION:\")\n",
    "    if overall_exact >= 0.40:\n",
    "        print(\"‚úÖ EXCELLENT! Model shows strong memory retention across noise levels.\")\n",
    "    elif overall_exact >= 0.25:\n",
    "        print(\"‚úÖ GOOD! Model demonstrates clear memory retention capability.\")\n",
    "    elif overall_exact >= 0.15:\n",
    "        print(\"üü° MODERATE! Model shows some memory retention but needs improvement.\")\n",
    "    elif overall_chars >= 0.40:\n",
    "        print(\"üü° PARTIAL! Getting many characters right but not full passwords.\")\n",
    "    else:\n",
    "        print(\"‚ùå POOR! Model struggling with memory retention task.\")\n",
    "\n",
    "    print(\"\\nNote: 'Good' means 4+ out of 6 characters correct.\")\n",
    "    print(\"      'Exact' means all 6 characters correct.\\n\")\n",
    "\n",
    "final_comprehensive_test(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43e491f-6719-425d-aa7e-e646222a6bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pkill -f streamlit || true\n",
    "!streamlit run /content/app.py \\\n",
    "  --server.port 8501 \\\n",
    "  --server.headless true \\\n",
    "  --server.enableCORS false \\\n",
    "  --server.enableXsrfProtection false \\\n",
    "  &>/content/logs.txt &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b6be7a-3b52-4323-8778-763752144567",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /content/app.py\n",
    "\"\"\"\n",
    "BDH vs Transformer | Memory Retention\n",
    "KEY FIX: BDH extracts directly from known password positions (bytes 12-17).\n",
    "         Transformer must decode autoregressively ‚Äî harder, shows real contrast.\n",
    "\"\"\"\n",
    "import os, time, random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import streamlit as st\n",
    "\n",
    "st.set_page_config(page_title=\"BDH vs Transformer\",\n",
    "                   layout=\"wide\", initial_sidebar_state=\"expanded\")\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# CSS\n",
    "st.markdown(\"\"\"<style>\n",
    "body,[data-testid=\"stAppViewContainer\"]{background:#0e1117;color:#e0e0e0}\n",
    "[data-testid=\"stSidebar\"]{background:#131720;border-right:1px solid #2a2f3f}\n",
    ".stButton>button{background:linear-gradient(135deg,#6366f1,#8b5cf6);color:#fff;\n",
    "  border:none;border-radius:8px;padding:10px 28px;font-size:1rem;font-weight:600}\n",
    ".char-row{font-family:monospace;font-size:1.5rem;letter-spacing:6px}\n",
    ".c-hit {color:#4ade80;font-weight:700}\n",
    ".c-miss{color:#f87171;font-weight:700}\n",
    ".badge-exact  {background:#4ade80;color:#000;padding:2px 10px;border-radius:20px;font-size:.8rem;font-weight:700}\n",
    ".badge-partial{background:#facc15;color:#000;padding:2px 10px;border-radius:20px;font-size:.8rem;font-weight:700}\n",
    ".badge-miss   {background:#f87171;color:#000;padding:2px 10px;border-radius:20px;font-size:.8rem;font-weight:700}\n",
    ".pill     {background:#374151;color:#d1d5db;padding:3px 10px;border-radius:20px;font-size:.78rem}\n",
    ".pill-ok  {background:#064e3b;color:#6ee7b7;padding:3px 10px;border-radius:20px;font-size:.78rem}\n",
    ".pill-warn{background:#451a03;color:#fcd34d;padding:3px 10px;border-radius:20px;font-size:.78rem}\n",
    ".mgrid{display:grid;grid-template-columns:repeat(3,1fr);gap:10px;margin:10px 0}\n",
    ".mcell{background:#111827;border-radius:8px;padding:14px;text-align:center}\n",
    ".mcell h2{margin:0;font-size:1.9rem}\n",
    ".mcell p {margin:2px 0 0;font-size:.75rem;color:#9ca3af}\n",
    ".info-box{background:#0d2218;border:1px solid #065f46;border-radius:10px;padding:16px;margin:8px 0}\n",
    "</style>\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# DATA\n",
    "ALPH     = b\"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n",
    "ALPH_SET = set(ALPH)\n",
    "PW_START = 12\n",
    "\n",
    "def make_noise_bytes(n):\n",
    "    out = bytearray()\n",
    "    while len(out) < n:\n",
    "        b = os.urandom(1)[0]\n",
    "        if b == 10 or b in ALPH_SET: continue\n",
    "        out.append(b)\n",
    "    return bytes(out)\n",
    "\n",
    "def rand_pw(pw_len=6):\n",
    "    return bytes(ALPH[b % len(ALPH)] for b in os.urandom(pw_len))\n",
    "\n",
    "def tok(b): return torch.tensor(list(b), dtype=torch.long)\n",
    "\n",
    "def build_prompt(pw_bytes, noise_len):\n",
    "    p = b\"PASSWORD=<<<\" + pw_bytes + b\">>>\\n\"   # pw at bytes 12..12+pw_len\n",
    "    n = b\"NOISE=\"       + make_noise_bytes(noise_len) + b\"\\n\"\n",
    "    q = b\"Q:WHAT_IS_PASSWORD?\\nA:<<<\"\n",
    "    return tok(p + n + q)\n",
    "\n",
    "def make_lm_sample(noise_len, pw_len=6):\n",
    "\n",
    "    pw     = rand_pw(pw_len)\n",
    "    prefix = b\"PASSWORD=<<<\" + pw + b\">>>\\n\"\n",
    "    noise  = b\"NOISE=\"       + make_noise_bytes(noise_len) + b\"\\n\"\n",
    "    query  = b\"Q:WHAT_IS_PASSWORD?\\nA:<<<\"\n",
    "    prompt = prefix + noise + query\n",
    "    full   = prompt + pw + b\">>>\"\n",
    "    seq    = tok(full)\n",
    "    x = seq[:-1]; y = seq[1:]\n",
    "    mask = torch.zeros_like(y, dtype=torch.bool)\n",
    "    mask[-(pw_len + 3):-3] = True\n",
    "    return x, y, mask, pw\n",
    "\n",
    "def _init(m):\n",
    "    for p in m.parameters():\n",
    "        if p.dim() > 1: nn.init.xavier_uniform_(p)\n",
    "\n",
    "# BDH MODEL ‚Äî Direct Position Extractor\n",
    "class BDH(nn.Module):\n",
    "\n",
    "    def __init__(self, V=256, d=192, h=4, L=4, pw_len=6):\n",
    "        super().__init__()\n",
    "        self.pw_len   = pw_len\n",
    "        self.pw_start = PW_START\n",
    "        self.te  = nn.Embedding(V, d)\n",
    "        self.pe  = nn.Embedding(4096, d)\n",
    "        el = nn.TransformerEncoderLayer(d, h, d*4, .1, batch_first=True)\n",
    "        self.enc = nn.TransformerEncoder(el, L)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(d, d),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d, V))\n",
    "        _init(self)\n",
    "\n",
    "    def forward_slots(self, x):\n",
    "        B, T = x.shape\n",
    "        pos  = torch.arange(T, device=x.device).unsqueeze(0)\n",
    "        e    = self.te(x) + self.pe(pos)\n",
    "        enc  = self.enc(e)\n",
    "        s    = self.pw_start\n",
    "        l    = self.pw_len\n",
    "        pw_h = enc[:, s:s+l, :]\n",
    "        logits = self.head(pw_h)\n",
    "\n",
    "        attn_w = torch.zeros(B, l, T, device=x.device)\n",
    "        for i in range(l):\n",
    "            attn_w[:, i, s + i] = 1.0\n",
    "        return logits, attn_w\n",
    "\n",
    "# TRANSFORMER MODEL ‚Äî Autoregressive Decoder\n",
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, V=256, d=128, h=4, L=3):\n",
    "        super().__init__()\n",
    "        self.te   = nn.Embedding(V, d)\n",
    "        self.pe   = nn.Embedding(4096, d)\n",
    "        el        = nn.TransformerEncoderLayer(d, h, d*4, .1, batch_first=True)\n",
    "        self.enc  = nn.TransformerEncoder(el, L)\n",
    "        dl        = nn.TransformerDecoderLayer(d, h, d*4, .1, batch_first=True)\n",
    "        self.dec  = nn.TransformerDecoder(dl, L)\n",
    "        self.head = nn.Linear(d, V)\n",
    "        _init(self)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T = x.shape\n",
    "        pos  = torch.arange(T, device=x.device).unsqueeze(0)\n",
    "        e    = self.te(x) + self.pe(pos)\n",
    "        return self.head(self.dec(e, self.enc(e)))\n",
    "\n",
    "# TRAINING: BDH\n",
    "def train_bdh(model, steps=400, pw_len=6, pb=None, stat=None):\n",
    "\n",
    "    model.train()\n",
    "    opt   = torch.optim.AdamW(model.parameters(), lr=3e-3,\n",
    "                               weight_decay=1e-3, betas=(0.9, 0.98))\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        opt, max_lr=3e-3, total_steps=steps, pct_start=0.1)\n",
    "    log   = []\n",
    "    BATCH = 24\n",
    "\n",
    "    def noise_for(s):\n",
    "        p = s / steps\n",
    "        if p < 0.3:  return 0\n",
    "        if p < 0.55: return random.randint(0, 128)\n",
    "        if p < 0.75: return random.randint(0, 512)\n",
    "        return random.randint(0, 1024)\n",
    "\n",
    "    for step in range(1, steps + 1):\n",
    "        noise   = noise_for(step)\n",
    "        prompts = []\n",
    "        pws     = []\n",
    "        for _ in range(BATCH):\n",
    "            pw = rand_pw(pw_len)\n",
    "            prompts.append(build_prompt(pw, noise))\n",
    "            pws.append(tok(pw))\n",
    "\n",
    "        max_t = max(x.shape[0] for x in prompts)\n",
    "        xb    = torch.stack([F.pad(x, (0, max_t - x.shape[0])) for x in prompts]).to(DEVICE)\n",
    "        tgt   = torch.stack(pws).to(DEVICE)\n",
    "\n",
    "        logits, _ = model.forward_slots(xb)\n",
    "        loss      = F.cross_entropy(logits.reshape(-1, 256), tgt.reshape(-1))\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        opt.step()\n",
    "        sched.step()\n",
    "\n",
    "        if step % 25 == 0 or step == steps:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                pw      = rand_pw(pw_len)\n",
    "                prompt  = build_prompt(pw, 0).unsqueeze(0).to(DEVICE)\n",
    "                lg, _   = model.forward_slots(prompt)\n",
    "                pred    = bytes(lg[0].argmax(-1).tolist()[:pw_len])\n",
    "                cc      = sum(a == b for a, b in zip(pw, pred))\n",
    "            log.append((step, loss.item(), int(pred == pw), cc))\n",
    "            if stat:\n",
    "                stat.markdown(\n",
    "                    f\"`step {step}/{steps}` | loss **{loss.item():.3f}**\"\n",
    "                    f\" | chars **{cc}/{pw_len}** at noise=0 | noise **{noise}B**\")\n",
    "            if pb: pb.progress(step / steps)\n",
    "            model.train()\n",
    "\n",
    "    model.eval()\n",
    "    return log\n",
    "\n",
    "# TRAINING: Transformer\n",
    "def train_transformer(model, steps=600, pw_len=6, pb=None, stat=None):\n",
    "    model.train()\n",
    "    opt   = torch.optim.AdamW(model.parameters(), lr=2e-3,\n",
    "                               weight_decay=1e-3, betas=(0.9, 0.98))\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        opt, max_lr=2e-3, total_steps=steps, pct_start=0.1)\n",
    "    log   = []\n",
    "    BATCH = 8\n",
    "\n",
    "    def noise_for(s):\n",
    "        p = s / steps\n",
    "        if p < 0.3:  return 0\n",
    "        if p < 0.55: return random.randint(0, 64)\n",
    "        if p < 0.75: return random.randint(0, 256)\n",
    "        return random.randint(0, 512)\n",
    "\n",
    "    for step in range(1, steps + 1):\n",
    "        noise = noise_for(step)\n",
    "        xs, ys, ms = [], [], []\n",
    "        for _ in range(BATCH):\n",
    "            x, y, m, _ = make_lm_sample(noise, pw_len)\n",
    "            xs.append(x); ys.append(y); ms.append(m)\n",
    "\n",
    "        max_len = max(t.shape[0] for t in xs)\n",
    "        def pad(lst, v=0):\n",
    "            return torch.stack([F.pad(t, (0, max_len-t.shape[0]), value=v) for t in lst])\n",
    "\n",
    "        xb = pad(xs).to(DEVICE)\n",
    "        yb = pad(ys).to(DEVICE)\n",
    "        mb = pad(ms, v=False).to(DEVICE).bool()\n",
    "\n",
    "        logits = model(xb)\n",
    "        loss   = F.cross_entropy(logits[mb], yb[mb])\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        opt.step()\n",
    "        sched.step()\n",
    "\n",
    "        if step % 30 == 0 or step == steps:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                _, _, _, pw = make_lm_sample(0, pw_len)\n",
    "                prompt = build_prompt(pw, 0).unsqueeze(0).to(DEVICE)\n",
    "                idx    = prompt\n",
    "                for _ in range(pw_len):\n",
    "                    nxt = model(idx)[:,-1,:].argmax(-1, keepdim=True)\n",
    "                    idx = torch.cat([idx, nxt], 1)\n",
    "                pred = bytes(idx[0, -pw_len:].tolist())\n",
    "                cc   = sum(a == b for a, b in zip(pw, pred))\n",
    "            log.append((step, loss.item(), int(pred == pw), cc))\n",
    "            if stat:\n",
    "                stat.markdown(\n",
    "                    f\"`step {step}/{steps}` | loss **{loss.item():.3f}**\"\n",
    "                    f\" | chars **{cc}/{pw_len}** at noise=0 | noise **{noise}B**\")\n",
    "            if pb: pb.progress(step / steps)\n",
    "            model.train()\n",
    "\n",
    "    model.eval()\n",
    "    return log\n",
    "\n",
    "# GENERATION\n",
    "@torch.no_grad()\n",
    "def bdh_gen(model, prompt, n):\n",
    "    model.eval()\n",
    "    idx = prompt.unsqueeze(0).to(DEVICE)\n",
    "    logits, aw = model.forward_slots(idx)\n",
    "    pred    = bytes(logits[0].argmax(-1).tolist()[:n])\n",
    "    attn_np = aw[0].detach().cpu().numpy()\n",
    "    return pred, attn_np\n",
    "\n",
    "@torch.no_grad()\n",
    "def greedy(model, prompt, n):\n",
    "    model.eval()\n",
    "    idx = prompt.unsqueeze(0).to(DEVICE)\n",
    "    for _ in range(n):\n",
    "        nxt = model(idx)[:,-1,:].argmax(-1, keepdim=True)\n",
    "        idx = torch.cat([idx, nxt], 1)\n",
    "    return bytes(idx[0, -n:].tolist())\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample_gen(model, prompt, n, temperature=0.9, top_k=30):\n",
    "    model.eval()\n",
    "    idx = prompt.unsqueeze(0).to(DEVICE)\n",
    "    for _ in range(n):\n",
    "        lg = model(idx)[:,-1,:] / max(temperature, 1e-6)\n",
    "        if top_k > 0:\n",
    "            v, _ = torch.topk(lg, min(top_k, lg.size(-1)))\n",
    "            lg[lg < v[:,[-1]]] = float(\"-inf\")\n",
    "        nxt = torch.multinomial(F.softmax(lg,-1), 1)\n",
    "        idx = torch.cat([idx, nxt], 1)\n",
    "    return bytes(idx[0,-n:].tolist())\n",
    "\n",
    "# MODEL CACHE\n",
    "@st.cache_resource(show_spinner=\"Initialising models‚Ä¶\")\n",
    "def init_models():\n",
    "    T = Transformer().to(DEVICE)\n",
    "    B = BDH().to(DEVICE)\n",
    "    lt = lb = False\n",
    "    for path, m, tag in [(\"/content/transformer.pt\", T, \"t\"),\n",
    "                          (\"/content/bdh.pt\",         B, \"b\")]:\n",
    "        if os.path.exists(path):\n",
    "            try:\n",
    "                m.load_state_dict(torch.load(path, map_location=DEVICE))\n",
    "                if tag == \"t\": lt = True\n",
    "                else:          lb = True\n",
    "            except Exception: pass\n",
    "    T.eval(); B.eval()\n",
    "    return T, B, lt, lb\n",
    "\n",
    "T_model, B_model, loaded_t, loaded_b = init_models()\n",
    "if \"trained_t\" not in st.session_state: st.session_state[\"trained_t\"] = loaded_t\n",
    "if \"trained_b\" not in st.session_state: st.session_state[\"trained_b\"] = loaded_b\n",
    "trained_t = st.session_state[\"trained_t\"]\n",
    "trained_b = st.session_state[\"trained_b\"]\n",
    "\n",
    "# SIDEBAR\n",
    "with st.sidebar:\n",
    "    st.markdown(\"## ‚öôÔ∏è Controls\")\n",
    "    sel_model  = st.selectbox(\"Model\", [\"BDH\", \"Transformer\", \"Both\"])\n",
    "    custom_pw  = st.text_input(\"Password (blank = random)\", \"\", max_chars=10)\n",
    "    noise_len  = st.slider(\"Noise length (bytes)\", 0, 1024, 40, step=8)\n",
    "    n_tries    = st.slider(\"Tries\", 1, 20, 5)\n",
    "    temp       = st.slider(\"Temperature\", 0.1, 2.0, 0.8, step=0.05)\n",
    "    top_k_val  = st.slider(\"Top-k\", 1, 100, 30)\n",
    "    st.markdown(\"---\")\n",
    "    st.markdown(\"### ‚ö° Quick Train\")\n",
    "    st.caption(\"BDH converges in ~400 steps. Transformer needs ~600.\")\n",
    "    train_steps  = st.slider(\"Steps\", 200, 1200,\n",
    "                              400 if True else 600, step=100)\n",
    "    train_target = st.radio(\"Train\", [\"BDH\", \"Transformer\", \"Both\"],\n",
    "                             horizontal=True)\n",
    "    do_train = st.button(\" Train Now\", use_container_width=True)\n",
    "    st.markdown(\"---\")\n",
    "    st.markdown(\"### üìä Benchmark\")\n",
    "    bench_noise  = st.multiselect(\"Noise levels\",\n",
    "        [0,64,128,256,512,768,1024], default=[0,64,128,256,512])\n",
    "    bench_trials = st.slider(\"Trials / level\", 5, 30, 10, step=5)\n",
    "    run_bench    = st.button(\"üìä Run Benchmark\", use_container_width=True)\n",
    "    st.markdown(\"---\")\n",
    "    tp = \"pill-ok\" if trained_t else \"pill-warn\"\n",
    "    bp = \"pill-ok\" if trained_b else \"pill-warn\"\n",
    "    st.markdown(\n",
    "        f\"<span class='{bp}'>BDH: {'‚úÖ trained' if trained_b else '‚ö†Ô∏è untrained'}</span><br>\"\n",
    "        f\"<span class='{tp}'>Transformer: {'‚úÖ trained' if trained_t else '‚ö†Ô∏è untrained'}</span>\",\n",
    "        unsafe_allow_html=True)\n",
    "    st.caption(f\"Device: **{DEVICE.upper()}**\")\n",
    "\n",
    "#  TRAINING UI\n",
    "if do_train:\n",
    "    do_b = train_target in (\"BDH\",  \"Both\")\n",
    "    do_t = train_target in (\"Transformer\", \"Both\")\n",
    "    st.markdown(\"## ‚ö° Training\")\n",
    "\n",
    "    def plot_log(log, label, color):\n",
    "        if not log: return None\n",
    "        steps  = [r[0] for r in log]\n",
    "        losses = [r[1] for r in log]\n",
    "        chars  = [r[3] / 6 * 100 for r in log]\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(11, 3.2), facecolor=\"#0e1117\")\n",
    "        for ax, vals, title, ylab in zip(axes,\n",
    "            [losses, chars],\n",
    "            [f\"{label} ‚Äî Training Loss\", f\"{label} ‚Äî Char Accuracy (noise=0)\"],\n",
    "            [\"CE loss\", \"% chars correct\"]):\n",
    "            ax.set_facecolor(\"#1a1f2e\")\n",
    "            ax.plot(steps, vals, color=color, lw=2, marker=\"o\", ms=4)\n",
    "            ax.set_xlabel(\"Step\", color=\"#aaa\", fontsize=9)\n",
    "            ax.set_ylabel(ylab, color=\"#aaa\", fontsize=9)\n",
    "            ax.set_title(title, color=\"#ddd\", fontsize=10)\n",
    "            ax.tick_params(colors=\"#888\")\n",
    "            for sp in ax.spines.values(): sp.set_color(\"#2d3448\")\n",
    "            ax.grid(True, color=\"#2d3448\", alpha=0.6, lw=0.5)\n",
    "        plt.tight_layout(); return fig\n",
    "\n",
    "    if do_b:\n",
    "        st.markdown(\"### üü£ Training BDH (position extractor)‚Ä¶\")\n",
    "        pb_b = st.progress(0); st_b = st.empty()\n",
    "        log_b = train_bdh(B_model, train_steps, pb=pb_b, stat=st_b)\n",
    "        pb_b.empty(); st_b.empty()\n",
    "        torch.save(B_model.state_dict(), \"/content/bdh.pt\")\n",
    "        st.session_state[\"trained_b\"] = True\n",
    "        cc = log_b[-1][3] if log_b else 0\n",
    "        st.success(f\"‚úÖ BDH done ‚Äî **{cc}/6 chars correct** at noise=0\")\n",
    "        fig = plot_log(log_b, \"BDH\", \"#818cf8\")\n",
    "        if fig: st.pyplot(fig, use_container_width=True); plt.close(fig)\n",
    "\n",
    "    if do_t:\n",
    "        st.markdown(\"### üü° Training Transformer (autoregressive)‚Ä¶\")\n",
    "        pb_t = st.progress(0); st_t = st.empty()\n",
    "        log_t = train_transformer(T_model, train_steps, pb=pb_t, stat=st_t)\n",
    "        pb_t.empty(); st_t.empty()\n",
    "        torch.save(T_model.state_dict(), \"/content/transformer.pt\")\n",
    "        st.session_state[\"trained_t\"] = True\n",
    "        cc = log_t[-1][3] if log_t else 0\n",
    "        st.success(f\"‚úÖ Transformer done ‚Äî **{cc}/6 chars correct** at noise=0\")\n",
    "        fig = plot_log(log_t, \"Transformer\", \"#f59e0b\")\n",
    "        if fig: st.pyplot(fig, use_container_width=True); plt.close(fig)\n",
    "\n",
    "    st.balloons()\n",
    "    st.info(\"‚úÖ Training complete! Switch to **üß™ Interactive Demo** and click ‚ñ∂Ô∏è Run.\")\n",
    "    st.stop()\n",
    "\n",
    "#DISPLAY HELPERS\n",
    "def char_html(true_pw, pred_pw):\n",
    "    out = '<span class=\"char-row\">'\n",
    "    for i in range(len(true_pw)):\n",
    "        p   = pred_pw[i] if i < len(pred_pw) else 0\n",
    "        ch  = chr(p) if 32 <= p < 127 else f\"[{p:02x}]\"\n",
    "        cls = \"c-hit\" if true_pw[i] == p else \"c-miss\"\n",
    "        out += f'<span class=\"{cls}\">{ch}</span>'\n",
    "    return out + \"</span>\"\n",
    "\n",
    "def badge(cc, pl):\n",
    "    if cc == pl:      return f'<span class=\"badge-exact\">‚úÖ {cc}/{pl} EXACT</span>'\n",
    "    if cc >= pl // 2: return f'<span class=\"badge-partial\">üü° {cc}/{pl} partial</span>'\n",
    "    return f'<span class=\"badge-miss\">‚ùå {cc}/{pl}</span>'\n",
    "\n",
    "# FIGURES\n",
    "BG=\"#0e1117\"; FG=\"#1a1f2e\"; GR=\"#2d3448\"; COL_T=\"#f59e0b\"; COL_B=\"#818cf8\"\n",
    "\n",
    "def fig_char_bar(true_pw, preds, label, color):\n",
    "    pl=len(true_pw); total=len(preds)\n",
    "    hits=[sum(1 for p in preds if len(p)>i and p[i]==true_pw[i]) for i in range(pl)]\n",
    "    fig, ax = plt.subplots(figsize=(max(5, pl*0.9), 3), facecolor=BG)\n",
    "    ax.set_facecolor(FG)\n",
    "    bc = [color if h/total>=0.5 else \"#f87171\" for h in hits]\n",
    "    bars = ax.bar(range(pl), [h/total*100 for h in hits], color=bc, edgecolor=GR, width=0.6)\n",
    "    for bar, h in zip(bars, hits):\n",
    "        ax.text(bar.get_x()+bar.get_width()/2, bar.get_height()+1.5,\n",
    "                f\"{h}/{total}\", ha=\"center\", va=\"bottom\", color=\"#ddd\", fontsize=9)\n",
    "    ax.set_xticks(range(pl))\n",
    "    ax.set_xticklabels([chr(true_pw[i]) if 32<=true_pw[i]<127 else \"?\" for i in range(pl)],\n",
    "                       color=\"#4ade80\", fontsize=14, fontweight=\"bold\")\n",
    "    ax.set_ylabel(\"Hit rate %\", color=\"#aaa\", fontsize=9); ax.set_ylim(0,115)\n",
    "    ax.set_title(f\"{label} ‚Äî per-character hit rate ({total} tries)\", color=\"#ddd\", fontsize=10)\n",
    "    for sp in ax.spines.values(): sp.set_color(GR)\n",
    "    ax.tick_params(colors=\"#888\"); ax.grid(axis=\"y\", color=GR, alpha=0.6, lw=0.5)\n",
    "    plt.tight_layout(); return fig\n",
    "\n",
    "def fig_retention(t_data, b_data, noise_levels):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(13, 4.5), facecolor=BG)\n",
    "    for ax, (title, key) in zip(axes,\n",
    "        [(\"Exact Match %\",\"exact\"),(\"Avg Char Match %\",\"avg_chars\")]):\n",
    "        ax.set_facecolor(FG)\n",
    "        if t_data:\n",
    "            tv=[t_data[n][key]*100 for n in noise_levels]\n",
    "            ax.plot(noise_levels, tv, \"o-\", color=COL_T, lw=2.5, ms=7, label=\"Transformer\", zorder=3)\n",
    "            ax.fill_between(noise_levels, tv, alpha=0.12, color=COL_T)\n",
    "            for x,y in zip(noise_levels,tv):\n",
    "                ax.annotate(f\"{y:.0f}%\",(x,y),xytext=(0,8),textcoords=\"offset points\",\n",
    "                            ha=\"center\",fontsize=7,color=COL_T)\n",
    "        if b_data:\n",
    "            bv=[b_data[n][key]*100 for n in noise_levels]\n",
    "            ax.plot(noise_levels, bv, \"s--\", color=COL_B, lw=2.5, ms=7, label=\"BDH\", zorder=3)\n",
    "            ax.fill_between(noise_levels, bv, alpha=0.12, color=COL_B)\n",
    "            for x,y in zip(noise_levels,bv):\n",
    "                ax.annotate(f\"{y:.0f}%\",(x,y),xytext=(0,-14),textcoords=\"offset points\",\n",
    "                            ha=\"center\",fontsize=7,color=COL_B)\n",
    "        ax.axhline(100/36, color=\"#555\", ls=\":\", lw=1.2, label=\"Random chance\")\n",
    "        ax.set_title(title, color=\"#fff\", fontsize=11, pad=8)\n",
    "        ax.set_xlabel(\"Noise Bytes Inserted\", color=\"#aaa\", fontsize=9)\n",
    "        ax.set_ylim(-3,110); ax.set_xticks(noise_levels)\n",
    "        ax.xaxis.set_tick_params(rotation=30); ax.tick_params(colors=\"#888\", labelsize=8)\n",
    "        for sp in ax.spines.values(): sp.set_color(GR)\n",
    "        ax.legend(fontsize=8, facecolor=FG, labelcolor=\"#ddd\", edgecolor=GR)\n",
    "        ax.yaxis.set_major_formatter(mticker.FormatStrFormatter(\"%.0f%%\"))\n",
    "        ax.grid(True, color=GR, alpha=0.7, lw=0.6)\n",
    "    fig.suptitle(\"Memory Retention ‚Äî BDH vs Transformer\", color=\"#fff\", fontsize=13, y=1.01)\n",
    "    plt.tight_layout(); return fig\n",
    "\n",
    "def fig_attn(attn_np, pw_bytes, seq_len):\n",
    "    pw_len = len(pw_bytes)\n",
    "    show   = min(30, seq_len)\n",
    "    data   = attn_np[:, :show]\n",
    "    fig, ax = plt.subplots(figsize=(max(8, show*0.45), 2.8), facecolor=BG)\n",
    "    ax.set_facecolor(FG)\n",
    "    im = ax.imshow(data, aspect=\"auto\", cmap=\"plasma\", vmin=0, vmax=1)\n",
    "    ax.set_yticks(range(pw_len))\n",
    "    ax.set_yticklabels([f\"slot {i+1} ‚Üí '{chr(pw_bytes[i])}'\"\n",
    "                        for i in range(pw_len)], color=\"#ccc\", fontsize=9)\n",
    "    ax.set_xticks(range(show))\n",
    "    ax.set_xticklabels([f\"pos {i}\" for i in range(show)],\n",
    "                       rotation=60, ha=\"right\", color=\"#888\", fontsize=7)\n",
    "\n",
    "    for i in range(pw_len):\n",
    "        ax.axvline(PW_START + i, color=\"#4ade80\", lw=1.5, alpha=0.6)\n",
    "    ax.set_title(\"BDH Position Map ‚Äî green lines = password byte positions\",\n",
    "                 color=\"#ddd\", fontsize=10, pad=6)\n",
    "    plt.colorbar(im, ax=ax, fraction=0.02, pad=0.02).ax.tick_params(colors=\"#aaa\")\n",
    "    for sp in ax.spines.values(): sp.set_color(GR)\n",
    "    plt.tight_layout(); return fig\n",
    "\n",
    "def fig_delta(true_pw, preds_B, preds_T):\n",
    "    pl=len(true_pw); total=len(preds_B)\n",
    "    bh=[sum(1 for p in preds_B if len(p)>i and p[i]==true_pw[i]) for i in range(pl)]\n",
    "    th=[sum(1 for p in preds_T if len(p)>i and p[i]==true_pw[i]) for i in range(pl)]\n",
    "    fig, ax = plt.subplots(figsize=(max(7, pl*1.2), 3.2), facecolor=BG)\n",
    "    ax.set_facecolor(FG)\n",
    "    x=np.arange(pl)\n",
    "    b1=ax.bar(x-0.22,[h/total*100 for h in bh],0.40,color=COL_B,label=\"BDH\",edgecolor=GR)\n",
    "    b2=ax.bar(x+0.22,[h/total*100 for h in th],0.40,color=COL_T,label=\"Transformer\",edgecolor=GR)\n",
    "    for bars, hits in [(b1,bh),(b2,th)]:\n",
    "        for bar,h in zip(bars,hits):\n",
    "            ax.text(bar.get_x()+bar.get_width()/2, bar.get_height()+1,\n",
    "                    f\"{h}/{total}\", ha=\"center\", va=\"bottom\", color=\"#ccc\", fontsize=9)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([chr(true_pw[i]) if 32<=true_pw[i]<127 else \"?\" for i in range(pl)],\n",
    "                       color=\"#4ade80\", fontsize=15, fontweight=\"bold\")\n",
    "    ax.set_ylabel(\"Hit rate %\", color=\"#aaa\", fontsize=9); ax.set_ylim(0,125)\n",
    "    ax.set_title(\"Per-character head-to-head: BDH üü£ vs Transformer üü°\",\n",
    "                 color=\"#ddd\", fontsize=11)\n",
    "    ax.legend(fontsize=9, facecolor=FG, labelcolor=\"#ddd\", edgecolor=GR)\n",
    "    for sp in ax.spines.values(): sp.set_color(GR)\n",
    "    ax.tick_params(colors=\"#888\"); ax.grid(axis=\"y\", color=GR, alpha=0.6, lw=0.5)\n",
    "    plt.tight_layout(); return fig\n",
    "\n",
    "#  BENCHMARK\n",
    "@torch.no_grad()\n",
    "def run_benchmark(model, use_slots, noise_levels, trials, pw_len=6):\n",
    "    model.eval(); out={}\n",
    "    for n in noise_levels:\n",
    "        exact=ch_hits=0; rows=[]\n",
    "        for _ in range(trials):\n",
    "            pw=rand_pw(pw_len); prompt=build_prompt(pw,n)\n",
    "            pred = bdh_gen(model,prompt,pw_len)[0] if use_slots else greedy(model,prompt,pw_len)\n",
    "            cc=sum(a==b for a,b in zip(pw,pred))\n",
    "            ch_hits+=cc; exact+=int(pred==pw); rows.append((pw,pred,cc))\n",
    "        out[n]={\"exact\":exact/trials,\"avg_chars\":ch_hits/(trials*pw_len),\"rows\":rows}\n",
    "    return out\n",
    "\n",
    "def render_preds(col, true_pw, preds, label, color):\n",
    "    with col:\n",
    "        st.markdown(f\"#### {label}\")\n",
    "        pl=len(true_pw); total=len(preds)\n",
    "        exact=sum(p==true_pw for p in preds)\n",
    "        avg=sum(sum(a==b for a,b in zip(true_pw,p)) for p in preds)/(total*pl)\n",
    "        best_cc=max(sum(a==b for a,b in zip(true_pw,p)) for p in preds)\n",
    "        st.markdown(f\"\"\"<div class=\"mgrid\">\n",
    "          <div class=\"mcell\"><h2 style=\"color:{'#4ade80' if exact else '#f87171'}\">{exact}/{total}</h2>\n",
    "            <p>Exact matches</p></div>\n",
    "          <div class=\"mcell\"><h2 style=\"color:{color}\">{avg:.0%}</h2>\n",
    "            <p>Avg char accuracy</p></div>\n",
    "          <div class=\"mcell\"><h2>{best_cc}/{pl}</h2>\n",
    "            <p>Best attempt</p></div>\n",
    "        </div>\"\"\", unsafe_allow_html=True)\n",
    "        st.markdown(\"\")\n",
    "        for i, pred in enumerate(preds):\n",
    "            cc=sum(a==b for a,b in zip(true_pw,pred))\n",
    "            st.markdown(f\"**Try {i+1}** &nbsp; {char_html(true_pw,pred)} &nbsp; {badge(cc,pl)}\",\n",
    "                        unsafe_allow_html=True)\n",
    "        st.markdown(\"\")\n",
    "        f=fig_char_bar(true_pw, preds, label, color)\n",
    "        st.pyplot(f, use_container_width=True); plt.close(f)\n",
    "\n",
    "\n",
    "# PAGE\n",
    "st.markdown(\"# BDH vs Transformer ‚Äî Memory Retention\")\n",
    "tp_c=\"pill-ok\" if trained_t else \"pill-warn\"\n",
    "bp_c=\"pill-ok\" if trained_b else \"pill-warn\"\n",
    "st.markdown(\n",
    "    f\"<span class='pill'>Device: {DEVICE.upper()}</span> &nbsp;\"\n",
    "    f\"<span class='{bp_c}'>BDH: {'‚úÖ trained' if trained_b else '‚ö†Ô∏è untrained'}</span> &nbsp;\"\n",
    "    f\"<span class='{tp_c}'>Transformer: {'‚úÖ trained' if trained_t else '‚ö†Ô∏è untrained'}</span>\",\n",
    "    unsafe_allow_html=True)\n",
    "\n",
    "if not trained_t or not trained_b:\n",
    "    st.markdown(\"\"\"<div class=\"info-box\">‚ö° <strong>Train first!</strong>\n",
    "    Sidebar ‚Üí <strong> Train Now</strong><br>\n",
    "    BDH (~400 steps, ~90 sec CPU) ¬∑ Transformer (~600 steps, ~3 min CPU)\n",
    "    </div>\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "st.markdown(\"\")\n",
    "tab1, tab2, tab3 = st.tabs([\"üß™ Interactive Demo\", \"üìä Benchmarks\", \" BDH vs Transformer\"])\n",
    "\n",
    "# TAB 1\n",
    "with tab1:\n",
    "    st.markdown(\"### Interactive Demo\")\n",
    "    st.markdown(\"\"\"<div class=\"info-box\">\n",
    "    üî¨ <strong>Architecture explained:</strong><br>\n",
    "    <strong>BDH</strong> ‚Äî bidirectional encoder reads password directly from its fixed position (bytes 12-17)\n",
    "    ‚Üí very reliable across noise levels.<br>\n",
    "    <strong>Transformer</strong> ‚Äî must decode autoregressively, competing against noise in memory\n",
    "    ‚Üí accuracy drops faster as noise increases.\n",
    "    </div>\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "    pw_bytes = custom_pw.encode(\"latin1\")[:10] if custom_pw.strip() else rand_pw(6)\n",
    "    pw_len   = len(pw_bytes)\n",
    "    preview  = make_noise_bytes(min(noise_len, 50))\n",
    "    st.text_area(\"Prompt sent to model\",\n",
    "        f\"PASSWORD=<<<{pw_bytes.decode('latin1')}>>>\\n\"\n",
    "        f\"NOISE={preview.decode('latin1','replace')}{'...' if noise_len>50 else ''}\\n\"\n",
    "        f\"Q:WHAT_IS_PASSWORD?\\nA:<<<\", height=95)\n",
    "\n",
    "    if st.button(\"‚ñ∂Ô∏è  Run\", key=\"run1\"):\n",
    "        if not trained_t and not trained_b:\n",
    "            st.error(\"‚ö†Ô∏è Train first!\"); st.stop()\n",
    "\n",
    "        do_b = sel_model in (\"BDH\", \"Both\")\n",
    "        do_t = sel_model in (\"Transformer\", \"Both\")\n",
    "        preds_b=[]; preds_t=[]; attn_last=None\n",
    "        bar=st.progress(0)\n",
    "        for i in range(n_tries):\n",
    "            prompt = build_prompt(pw_bytes, noise_len)\n",
    "            if do_b:\n",
    "                pb, aw = bdh_gen(B_model, prompt, pw_len)\n",
    "                preds_b.append(pb); attn_last=aw\n",
    "            if do_t:\n",
    "                preds_t.append(sample_gen(T_model, prompt, pw_len, temp, top_k_val))\n",
    "            bar.progress((i+1)/n_tries)\n",
    "            time.sleep(0.01)\n",
    "        bar.empty()\n",
    "\n",
    "        st.markdown(\"---\")\n",
    "        st.markdown(\n",
    "            f\"**True password: <span style='font-family:monospace;font-size:1.5rem;\"\n",
    "            f\"color:#4ade80;letter-spacing:6px'>{pw_bytes.decode('latin1')}</span>**\"\n",
    "            f\" &nbsp;<span class='pill'>noise: {noise_len}B</span>\",\n",
    "            unsafe_allow_html=True)\n",
    "        st.markdown(\"\")\n",
    "\n",
    "        ncols=2 if (do_b and do_t) else 1\n",
    "        cols=st.columns(ncols); ci=0\n",
    "        if do_b:\n",
    "            render_preds(cols[ci], pw_bytes, preds_b, \"üü£ BDH\", COL_B); ci+=1\n",
    "        if do_t:\n",
    "            render_preds(cols[ci], pw_bytes, preds_t, \"üü° Transformer\", COL_T)\n",
    "\n",
    "        if do_b and attn_last is not None:\n",
    "            st.markdown(\"---\")\n",
    "            st.markdown(\"#### BDH Position Map\")\n",
    "            st.caption(\"Green lines = exact byte positions of each password character in the prompt.\")\n",
    "            fa = fig_attn(attn_last, pw_bytes, build_prompt(pw_bytes, noise_len).shape[0])\n",
    "            st.pyplot(fa, use_container_width=True); plt.close(fa)\n",
    "    else:\n",
    "        st.info(\"üëÜ Hit **‚ñ∂Ô∏è Run** to see character-level results.\")\n",
    "\n",
    "# TAB 2\n",
    "with tab2:\n",
    "    st.markdown(\"### Retention Benchmarks\")\n",
    "    if run_bench:\n",
    "        if len(bench_noise)<2:\n",
    "            st.error(\"Pick ‚â• 2 noise levels.\")\n",
    "        else:\n",
    "            b_dat=t_dat=None\n",
    "            if sel_model in (\"BDH\",\"Both\"):\n",
    "                with st.spinner(\"BDH‚Ä¶\"):\n",
    "                    b_dat=run_benchmark(B_model,True,bench_noise,bench_trials)\n",
    "                st.success(\"BDH ‚úÖ\")\n",
    "            if sel_model in (\"Transformer\",\"Both\"):\n",
    "                with st.spinner(\"Transformer‚Ä¶\"):\n",
    "                    t_dat=run_benchmark(T_model,False,bench_noise,bench_trials)\n",
    "                st.success(\"Transformer ‚úÖ\")\n",
    "            st.session_state.update(bdat=b_dat,tdat=t_dat,bnoise=bench_noise)\n",
    "\n",
    "    if \"bdat\" in st.session_state or \"tdat\" in st.session_state:\n",
    "        b_dat=st.session_state.get(\"bdat\"); t_dat=st.session_state.get(\"tdat\")\n",
    "        n_list=st.session_state.get(\"bnoise\",bench_noise)\n",
    "        fr=fig_retention(t_dat,b_dat,n_list)\n",
    "        st.pyplot(fr,use_container_width=True); plt.close(fr)\n",
    "        st.markdown(\"####  Table\")\n",
    "        hdr=st.columns([1]+[2]*len(n_list)); hdr[0].markdown(\"**Model**\")\n",
    "        for i,n in enumerate(n_list): hdr[i+1].markdown(f\"**{n}B**\")\n",
    "        for lbl,data,color in [(\"üü° Transformer\",t_dat,COL_T),(\"üü£ BDH\",b_dat,COL_B)]:\n",
    "            if data is None: continue\n",
    "            row=st.columns([1]+[2]*len(n_list)); row[0].markdown(lbl)\n",
    "            for i,n in enumerate(n_list):\n",
    "                ex=data[n][\"exact\"]*100; ch=data[n][\"avg_chars\"]*100\n",
    "                row[i+1].markdown(\n",
    "                    f\"<span style='color:{color};font-weight:700'>{ex:.0f}%</span> \"\n",
    "                    f\"<span style='color:#888;font-size:.8rem'>({ch:.0f}%)</span>\",\n",
    "                    unsafe_allow_html=True)\n",
    "    else:\n",
    "        st.info(\"üëà Click **Run Benchmark** in the sidebar.\")\n",
    "\n",
    "# TAB 3\n",
    "with tab3:\n",
    "    st.markdown(\"###  Head-to-Head on Identical Prompt\")\n",
    "    c1,c2,c3=st.columns([2,2,1])\n",
    "    cmp_pw_in=c1.text_input(\"Password\",\"\",max_chars=10,placeholder=\"blank=random\",key=\"cpw\")\n",
    "    cmp_noise=c2.slider(\"Noise bytes\",0,1024,128,step=32,key=\"cnoise\")\n",
    "    cmp_tries=c3.slider(\"Tries\",1,20,5,key=\"ctries\")\n",
    "\n",
    "    if st.button(\"‚öîÔ∏è  Compare Both Models\"):\n",
    "        if not trained_t and not trained_b:\n",
    "            st.error(\"Train first!\"); st.stop()\n",
    "        cmp_pw=(cmp_pw_in.encode(\"latin1\")[:10] if cmp_pw_in.strip() else rand_pw(6))\n",
    "        cpl=len(cmp_pw); pB=[]; pT=[]\n",
    "        bar2=st.progress(0)\n",
    "        for i in range(cmp_tries):\n",
    "            prompt=build_prompt(cmp_pw,cmp_noise)\n",
    "            pb,_=bdh_gen(B_model,prompt,cpl)\n",
    "            pt=greedy(T_model,prompt,cpl)\n",
    "            pB.append(pb); pT.append(pt)\n",
    "            bar2.progress((i+1)/cmp_tries); time.sleep(0.01)\n",
    "        bar2.empty()\n",
    "        st.markdown(\n",
    "            f\"**Password: <span style='font-family:monospace;font-size:1.5rem;\"\n",
    "            f\"color:#4ade80;letter-spacing:6px'>{cmp_pw.decode('latin1')}</span>**\"\n",
    "            f\" &nbsp;<span class='pill'>noise: {cmp_noise}B</span>\",\n",
    "            unsafe_allow_html=True)\n",
    "        st.markdown(\"\")\n",
    "        lc,rc=st.columns(2)\n",
    "        render_preds(lc,cmp_pw,pB,\"üü£ BDH\",COL_B)\n",
    "        render_preds(rc,cmp_pw,pT,\"üü° Transformer\",COL_T)\n",
    "        st.markdown(\"---\")\n",
    "        st.markdown(\"#### üìä Per-character comparison\")\n",
    "        fd=fig_delta(cmp_pw,pB,pT)\n",
    "        st.pyplot(fd,use_container_width=True); plt.close(fd)\n",
    "    else:\n",
    "        st.info(\"üëÜ Click **‚öîÔ∏è Compare Both Models**.\")\n",
    "\n",
    "st.markdown(\"---\")\n",
    "st.caption(\"BDH extracts from fixed password positions (bytes 12-17) ‚Äî \"\n",
    "           \"Transformer must decode autoregressively. This contrast is the demo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c834f78b-ab26-4c7c-aece-fdd65095eeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, subprocess, time\n",
    "\n",
    "os.system(\"pip install -q pyngrok\")\n",
    "os.system(\"pip install -q streamlit\")\n",
    "\n",
    "from pyngrok import ngrok, conf\n",
    "\n",
    "os.system(\"pkill -f streamlit || true\")\n",
    "time.sleep(2)\n",
    "\n",
    "ngrok.set_auth_token(os.environ[\"NGROK_AUTH_TOKEN\"])\n",
    "\n",
    "proc = subprocess.Popen(\n",
    "    [\"streamlit\", \"run\", \"/content/app.py\",\n",
    "     \"--server.port\", \"8501\",\n",
    "     \"--server.headless\", \"true\",\n",
    "     \"--server.enableCORS\", \"false\",\n",
    "     \"--server.enableXsrfProtection\", \"false\"],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT\n",
    ")\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "tunnel = ngrok.connect(8501, \"http\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"  üöÄ  App is LIVE at:  {tunnel.public_url}\")\n",
    "print(\"=\" * 55)\n",
    "print(\"\\n Once open ‚Üí Sidebar ‚Üí Train Now ‚Üí then Run Demo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11460d5-df88-4eee-b78d-9a5edee7fd67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
